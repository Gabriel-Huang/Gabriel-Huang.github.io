<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

  <meta content="width=device-width, initial-scale=1" name="viewport">
  <title>Gabriel (Jiahui) Huang</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', '');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link href="./css/fontawesome.all.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet">
  <link href="./css/bulma.min.css" rel="stylesheet">
  <link href="./css/cv.css" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
</head>

<body>

  <section>
    <div class="container is-max-desktop">
      <div class="columns is-vcentered">
        <div class="column">
          <h1 class="title is-2">Gabriel (Jiahui) Huang</h1>
          <h1 class="subtitle is-5">Research Engineer</h1>
        </div>
        <div class="column is-narrow portrait-column">
          <img class="portrait-image" src="./images/portrait.jpg" alt="A portrait of Keunhong Park" />
        </div>
        <div class="column has-text-right">
          <p>
            <a href="http://localhost:4000">
              <i class="fas fa-home"></i>
              
              localhost:4000
            </a>
          </p>
          <p>
            <a href="https://github.com/Gabriel-Huang">
              <i class="fab fa-github"></i>
              Gabriel-Huang
            </a>
          </p>
          <p>
            <a href="https://twitter.com/">
              <i class="fab fa-twitter"></i>
              
            </a>
          </p>
          <p>
            <a href="mailto:jiahuih@adobe.com">
              <i class="fas fa-envelope"></i>
              jiahuih@adobe.com
            </a>
          </p>
        </div>
      </div>

      <div class="content">
        <h2>Education</h2>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <b>University of British Columnbia</b><br />
            Msc in Computer Science, advised by <a href="https://smseitz.com">Steven M. Seitz</a> and <a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a>.<br /> Supported by Samsung Scholarship 2015-2020 ($50,000/year for 5 years)
          </div>
          <div class="column is-one-fifths has-text-right">
            Fall 2015 - Spring 2022
          </div>
        </div>
        

        <h2>Employment</h2>

        
        <div class="columns">
          <div class="column is-four-fifths">
            <b>Adobe</b><br />
            Research Scientist
          </div>
          <div class="column is-one-fifths has-text-right">
            Feb 2023 - Current
            <br />
            Vancouver, BC
          </div>
        </div>
        

        <h2>Publications</h2>

        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://seurat-cvpr.github.io/"><b>Seurat: From Moving Points to Depth</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://seokju-cho.github.io/">S. Cho</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://cvlab.korea.ac.kr/members">S. Kim</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://joonyoung-cv.github.io/">J. Lee</a>
                
              </span>
              
            </div>
            Inferring depth from point trajectories
          </div>
          <div class="column is-one-fifths has-text-right">
            CVPR, 2025
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://cvlab-kaist.github.io/Chrono/"><b>Exploring Temporally-Aware Features for Point Tracking</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://ines-hyeonsu-kim.github.io/">I. Kim</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://seokju-cho.github.io/">S. Cho</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://github.com/YJ-142150">J. Yi</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://joonyoung-cv.github.io/">J. Lee</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://cvlab.korea.ac.kr/members">S. Kim</a>
                
              </span>
              
            </div>
            A feature backbone for point tracking with built-in temporal awareness
          </div>
          <div class="column is-one-fifths has-text-right">
            CVPR, 2025
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://motion-canvas25.github.io/"><b>MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://doubiiu.github.io/">J. Xing</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://mai-t-long.com/">L. Mai</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://cusuh.github.io/">C. Ham</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://anime26398.github.io/">A. Mahapatra</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.cse.cuhk.edu.hk/~cwfu/">C. Fu</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://ttwong12.github.io/myself.html">T. Wong</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://scholar.google.com/citations?user=uiqXutMAAAAJ&hl=en">F. Liu</a>
                
              </span>
              
            </div>
            A model that integrates user-driven controls into image-to-video (I2V) generation models
          </div>
          <div class="column is-one-fifths has-text-right">
            SIGGRAPH, 2025
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://ku-cvlab.github.io/locotrack/"><b>LocoTrack: Local All-Pair Correspondence for Point Tracking</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://seokju-cho.github.io/">S. Cho</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://nam-jisu.github.io/">J. Nam</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://hg010303.github.io/">H. An</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://cvlab.korea.ac.kr/members">S. Kim</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://joonyoung-cv.github.io/">J. Lee</a>
                
              </span>
              
            </div>
            A highly accurate and efficient model for point tracking.
          </div>
          <div class="column is-one-fifths has-text-right">
            ECCV, 2024
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href=""><b>FlowTrack: Revisiting Optical Flow for Long-Range Dense Tracking</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://seokju-cho.github.io/">S. Cho</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://cvlab.korea.ac.kr/members">S. Kim</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://joonyoung-cv.github.io/">J. Lee</a>
                
              </span>
              
            </div>
            Dense point tracking on long-range videos.
          </div>
          <div class="column is-one-fifths has-text-right">
            CVPR, 2024
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://gabriel-huang.github.io/inve/"><b>INVE: Interactive Neural Video Editing</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.cs.ubc.ca/~lsigal/">L. Sigal</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.cs.ubc.ca/~kmyi/">K. Yi</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="http://www.oliverwang.info/">O. Wang</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://joonyoung-cv.github.io/">J. Lee</a>
                
              </span>
              
            </div>
            A real-time video editing pipeline via edits propagation.
          </div>
          <div class="column is-one-fifths has-text-right">
            CGI, 2023
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href="https://gabriel-huang.github.io/layered_controllable_video_generation/"><b>Layered Controllable Video Generation</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://scholar.google.ca/citations?user=oAYi1YQAAAAJ&hl=en">Y. Jin</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.cs.ubc.ca/~kmyi/">K. Yi</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.cs.ubc.ca/~lsigal/">L. Sigal</a>
                
              </span>
              
            </div>
            Using masks to control the generation of videos.
          </div>
          <div class="column is-one-fifths has-text-right">
            ECCV, 2022
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href=""><b>Single Image Video Prediction with Auto-Regressive GANs</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://chiayewken.com/">Y. Chia</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://samsonyubaijian.github.io/">S. Yu</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://github.com/yee-kevin">K. Yee</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.uni-bremen.de/csl/institut/team/mitarbeiter/dr-dennis-kuester">D. KÃ¼ster</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://www.ucl.ac.uk/pals/research/experimental-psychology/person/eva-krumhuber/">E. Krumhuber</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://dorienherremans.com/">D. Herremans</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">G. Roig</a>
                
              </span>
              
            </div>
            Animating facial expressions using GANs in an auto-regressive fashion.
          </div>
          <div class="column is-one-fifths has-text-right">
            Sensors, Volume 22
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href=""><b>Duality diagram similarity: a generic framework for initialization selection in task transfer learning</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block ">
                
                <a href="https://kshitijd20.github.io/">K. Dwivedi</a>,
                
              </span>
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">G. Roig</a>
                
              </span>
              
            </div>
            A metric that measures the similarity between neural networks.
          </div>
          <div class="column is-one-fifths has-text-right">
            ECCV, 2020
          </div>
        </div>
        
        <div class="columns">
          <div class="column is-four-fifths">
            <a href=""><b>Deep Anchored Convolutional Neural Networks</b></a>
            <div class="publication-authors">
              
              
              <span class="author-block author-me">
                
                J. Huang,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="https://kshitijd20.github.io/">K. Dwivedi</a>,
                
              </span>
              
              
              <span class="author-block ">
                
                <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">G. Roig</a>
                
              </span>
              
            </div>
            A highly efficitn neural network architecture that reuses weights from different layres.
          </div>
          <div class="column is-one-fifths has-text-right">
            CVPR Workshops, 2019
          </div>
        </div>
        
      </div>
    </div>
  </section>

</body>

</html>
